{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Privacy Package\n",
    "from privacy.analysis.rdp_accountant import compute_rdp\n",
    "from privacy.analysis.rdp_accountant import get_privacy_spent\n",
    "from privacy.optimizers.dp_optimizer import DPGradientDescentGaussianOptimizer\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epsilon(steps, noise_multiplier, batch_size):\n",
    "    if noise_multiplier == 0.0:\n",
    "        return float('inf')\n",
    "    orders = [1 + x / 10. for x in range(1, 100)] + list(range(12, 64))\n",
    "    sampling_probability = batch_size / 60000\n",
    "    rdp = compute_rdp(q=sampling_probability,\n",
    "                    noise_multiplier=noise_multiplier,\n",
    "                    steps=steps,\n",
    "                    orders=orders)\n",
    "    return get_privacy_spent(orders, rdp, target_delta=1e-5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_df(datafile):\n",
    "    data = pd.read_csv(datafile)\n",
    "    data = data.sample(frac=1, axis=0).reset_index(drop=True)\n",
    "    \n",
    "    predictors_df = data.drop(['action_taken_name'], axis=1)\n",
    "    predictors_df = predictors_df.drop(predictors_df.columns[0], axis=1)\n",
    "    \n",
    "    target_df = data['action_taken_name']\n",
    "    \n",
    "    n_cols = predictors_df.shape[1]\n",
    "    \n",
    "    return n_cols, predictors_df, target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_model(datafile='nc_sc_ga_va_clean_v0.csv', kfold_n_splits=5, kfold_n_repeats=1, epochs=10, batch_size=256, validation_split=0.2, learning_rate=0.15, l2_norm_clip =1, microbatches=1):\n",
    "    \n",
    "    # Roughly corresponds to epsilon of [infinity (non-private), 2, 1, 0.5, 0.25, 0.125, 0.2, 0.188]\n",
    "    noise_multipliers = [0, 0.84262, 1.145, 1.61203, 2.357066, 4, 10]\n",
    "    \n",
    "    # Process datafile\n",
    "    n_cols, X, Y = data_processing_df(datafile)\n",
    "\n",
    "    # Create kfold obejct\n",
    "    seed = 2019\n",
    "    np.random.seed(seed)\n",
    "    kfold = RepeatedStratifiedKFold(n_splits=kfold_n_splits, n_repeats=1, random_state=seed)    \n",
    "\n",
    "    # Train model based on different noise multipliers (different epsilons)\n",
    "    for nm in noise_multipliers:\n",
    "        eps = compute_epsilon(epochs * 60000 // batch_size, nm, batch_size)\n",
    "        kfold_results = []\n",
    "        for train_indices, test_indices in kfold.split(X, Y):\n",
    "            \n",
    "            # Define private optimizer\n",
    "            optimizer = DPGradientDescentGaussianOptimizer(\n",
    "                l2_norm_clip=l2_norm_clip,\n",
    "                noise_multiplier=nm,\n",
    "                num_microbatches=microbatches,\n",
    "                learning_rate=learning_rate,\n",
    "                unroll_microbatches=True)\n",
    "\n",
    "            # Define layers\n",
    "            model = keras.models.Sequential([\n",
    "                    keras.layers.Dense(32, activation=tf.nn.relu, input_shape = (n_cols,)),\n",
    "                    keras.layers.Dense(25, activation=tf.nn.softmax),\n",
    "                    keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "                    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "                ])\n",
    "            \n",
    "            # Compile model\n",
    "            model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics=['accuracy', auc])\n",
    "\n",
    "            # Split training and testing data based on k-fold split\n",
    "            x_train = X.values[train_indices]\n",
    "            y_train = to_categorical(Y.values[train_indices])\n",
    "            x_test = X.values[test_indices]\n",
    "            y_test = to_categorical(Y.values[test_indices])\n",
    "\n",
    "            # Train model\n",
    "            model.fit(x_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size, verbose = 0, shuffle=True)\n",
    "            \n",
    "            # Evaluate model\n",
    "            results = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
    "            kfold_results.append(list(results))\n",
    "\n",
    "        kfold_results.append([np.mean(item) for item in np.transpose(kfold_results)])\n",
    "        table = kfold_results\n",
    "        header = ['Loss', 'Accuracy', 'AUC']\n",
    "        rowIndex = ['Split {}'.format(item) for item in range(kfold_n_splits)]\n",
    "        rowIndex.append('Mean')\n",
    "        print(tabulate(table, headers=header, showindex=rowIndex, floatfmt=\".4f\"))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "run_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
