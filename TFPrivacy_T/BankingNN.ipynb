{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0711 09:33:14.304923 140304495933248 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0711 09:33:14.320287 140304495933248 deprecation_wrapper.py:119] From /home/thomas/Downloads/privacy/privacy/optimizers/dp_optimizer.py:230: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "W0711 09:33:14.322171 140304495933248 deprecation_wrapper.py:119] From /home/thomas/Downloads/privacy/privacy/optimizers/dp_optimizer.py:231: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0711 09:33:14.324059 140304495933248 deprecation_wrapper.py:119] From /home/thomas/Downloads/privacy/privacy/optimizers/dp_optimizer.py:232: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "W0711 09:33:14.326312 140304495933248 deprecation_wrapper.py:119] From /home/thomas/Downloads/privacy/privacy/optimizers/dp_optimizer.py:35: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import privacy\n",
    "print(tf.__version__)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract_to_msamd_income</th>\n",
       "      <th>population</th>\n",
       "      <th>minority_population</th>\n",
       "      <th>number_of_owner_occupied_units</th>\n",
       "      <th>number_of_1_to_4_family_units</th>\n",
       "      <th>loan_amount_000s</th>\n",
       "      <th>hud_median_family_income</th>\n",
       "      <th>applicant_income_000s</th>\n",
       "      <th>property_type_name</th>\n",
       "      <th>owner_occupancy_name</th>\n",
       "      <th>loan_type_name</th>\n",
       "      <th>loan_purpose_name</th>\n",
       "      <th>lien_status_name</th>\n",
       "      <th>co_applicant_sex_name</th>\n",
       "      <th>applicant_sex_name</th>\n",
       "      <th>applicant_race_name_1</th>\n",
       "      <th>applicant_ethnicity_name</th>\n",
       "      <th>agency_abbr</th>\n",
       "      <th>state_abbr_VA</th>\n",
       "      <th>action_taken_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83283</th>\n",
       "      <td>0.580755</td>\n",
       "      <td>0.270304</td>\n",
       "      <td>0.263382</td>\n",
       "      <td>0.390418</td>\n",
       "      <td>0.411782</td>\n",
       "      <td>0.126967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144080</th>\n",
       "      <td>0.672752</td>\n",
       "      <td>0.603743</td>\n",
       "      <td>0.449440</td>\n",
       "      <td>0.645359</td>\n",
       "      <td>0.656490</td>\n",
       "      <td>0.466509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327474</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201473</th>\n",
       "      <td>0.699785</td>\n",
       "      <td>0.639761</td>\n",
       "      <td>0.366584</td>\n",
       "      <td>0.735303</td>\n",
       "      <td>0.734265</td>\n",
       "      <td>0.414757</td>\n",
       "      <td>0.272560</td>\n",
       "      <td>0.333182</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193424</th>\n",
       "      <td>0.759269</td>\n",
       "      <td>0.675982</td>\n",
       "      <td>0.406777</td>\n",
       "      <td>0.750315</td>\n",
       "      <td>0.724571</td>\n",
       "      <td>0.438675</td>\n",
       "      <td>0.362799</td>\n",
       "      <td>0.381058</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94775</th>\n",
       "      <td>0.720665</td>\n",
       "      <td>0.489062</td>\n",
       "      <td>0.219632</td>\n",
       "      <td>0.569032</td>\n",
       "      <td>0.605935</td>\n",
       "      <td>0.400866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317374</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tract_to_msamd_income  population  minority_population  \\\n",
       "83283                0.580755    0.270304             0.263382   \n",
       "144080               0.672752    0.603743             0.449440   \n",
       "201473               0.699785    0.639761             0.366584   \n",
       "193424               0.759269    0.675982             0.406777   \n",
       "94775                0.720665    0.489062             0.219632   \n",
       "\n",
       "        number_of_owner_occupied_units  number_of_1_to_4_family_units  \\\n",
       "83283                         0.390418                       0.411782   \n",
       "144080                        0.645359                       0.656490   \n",
       "201473                        0.735303                       0.734265   \n",
       "193424                        0.750315                       0.724571   \n",
       "94775                         0.569032                       0.605935   \n",
       "\n",
       "        loan_amount_000s  hud_median_family_income  applicant_income_000s  \\\n",
       "83283           0.126967                  0.000000               0.260453   \n",
       "144080          0.466509                  1.000000               0.327474   \n",
       "201473          0.414757                  0.272560               0.333182   \n",
       "193424          0.438675                  0.362799               0.381058   \n",
       "94775           0.400866                  0.000000               0.317374   \n",
       "\n",
       "        property_type_name  owner_occupancy_name  loan_type_name  \\\n",
       "83283                    0                     1               1   \n",
       "144080                   1                     1               1   \n",
       "201473                   1                     1               0   \n",
       "193424                   1                     1               1   \n",
       "94775                    1                     1               1   \n",
       "\n",
       "        loan_purpose_name  lien_status_name  co_applicant_sex_name  \\\n",
       "83283                   0                 0                      0   \n",
       "144080                  1                 1                      0   \n",
       "201473                  0                 1                      1   \n",
       "193424                  0                 1                      0   \n",
       "94775                   0                 1                      1   \n",
       "\n",
       "        applicant_sex_name  applicant_race_name_1  applicant_ethnicity_name  \\\n",
       "83283                    0                      1                         1   \n",
       "144080                   1                      1                         1   \n",
       "201473                   1                      0                         1   \n",
       "193424                   0                      1                         1   \n",
       "94775                    1                      1                         1   \n",
       "\n",
       "        agency_abbr  state_abbr_VA  action_taken_name  \n",
       "83283             0              1                  1  \n",
       "144080            0              1                  1  \n",
       "201473            1              1                  0  \n",
       "193424            1              1                  0  \n",
       "94775             1              1                  1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/hmda_va_clean.csv\")\n",
    "dataevensamp = pd.concat([(data[data[\"action_taken_name\"] == 1]).sample(n=len(data[data[\"action_taken_name\"]==0])),\n",
    "                          data[data[\"action_taken_name\"]==0]])\n",
    "data = dataevensamp.sample(frac=1).iloc[:,1:]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[['tract_to_msamd_income', 'population', 'minority_population', 'number_of_owner_occupied_units','number_of_1_to_4_family_units','loan_amount_000s','hud_median_family_income', 'applicant_income_000s']].hist(bins=100, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxMinScaling\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "#data[['tract_to_msamd_income', 'population', 'minority_population', 'number_of_owner_occupied_units','number_of_1_to_4_family_units','loan_amount_000s','hud_median_family_income', 'applicant_income_000s']] = scaler.fit_transform(data[['tract_to_msamd_income', 'population', 'minority_population', 'number_of_owner_occupied_units','number_of_1_to_4_family_units','loan_amount_000s','hud_median_family_income', 'applicant_income_000s']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[['tract_to_msamd_income', 'population', 'minority_population', 'number_of_owner_occupied_units','number_of_1_to_4_family_units','loan_amount_000s','hud_median_family_income', 'applicant_income_000s']].hist(bins=100, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = data.iloc[:,0:-1].values\n",
    "labels = pd.to_numeric(data.iloc[:,-1], downcast='integer').values\n",
    "from keras.utils import to_categorical\n",
    "labels = to_categorical(labels)\n",
    "x_train, x_test, y_train, y_test = train_test_split(predictors, labels, test_size=.2)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. INSTANTIATE\n",
    "#enc = sklearn.preprocessing.OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "#enc.fit(data.drop(['approved'], axis=1))\n",
    "\n",
    "# 3. Transform\n",
    "#onehotlabels = enc.transform(data.drop(['approved'], axis=1)).toarray()\n",
    "#predictors = pd.DataFrame(onehotlabels).values\n",
    "#labels = pd.to_numeric(data.iloc[:,-1], downcast='integer').values\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(onehotlabels, labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creation(optimizer='adam', loss='categorical_crossentropy'):    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(100, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(25, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(20, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer,\n",
    "             loss=loss,\n",
    "             metrics=['accuracy', auc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64787 samples, validate on 16197 samples\n",
      "Epoch 1/5\n",
      "64787/64787 [==============================] - 23s 355us/step - loss: 0.5812 - acc: 0.6975 - auc: 0.7402 - val_loss: 0.5659 - val_acc: 0.7092 - val_auc: 0.7627\n",
      "Epoch 2/5\n",
      "64787/64787 [==============================] - 11s 171us/step - loss: 0.5643 - acc: 0.7086 - auc: 0.7673 - val_loss: 0.5650 - val_acc: 0.7072 - val_auc: 0.7701\n",
      "Epoch 3/5\n",
      "64787/64787 [==============================] - 11s 166us/step - loss: 0.5601 - acc: 0.7105 - auc: 0.7719 - val_loss: 0.5601 - val_acc: 0.7136 - val_auc: 0.7736\n",
      "Epoch 4/5\n",
      "64787/64787 [==============================] - 11s 166us/step - loss: 0.5578 - acc: 0.7103 - auc: 0.7749 - val_loss: 0.5564 - val_acc: 0.7141 - val_auc: 0.7758\n",
      "Epoch 5/5\n",
      "64787/64787 [==============================] - 12s 186us/step - loss: 0.5548 - acc: 0.7119 - auc: 0.7767 - val_loss: 0.5551 - val_acc: 0.7135 - val_auc: 0.7776\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 100)               2000      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                520       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,087\n",
      "Trainable params: 5,087\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_creation()\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.52286166e-01, -2.49711946e-01, -9.78391171e-02,\n",
       "         -1.56426966e-01,  1.46167010e-01,  1.83359757e-01,\n",
       "         -1.73424721e-01,  5.55609129e-02, -2.32354283e-01,\n",
       "         -1.21092297e-01,  7.82404095e-03, -2.07624167e-01,\n",
       "          5.39621264e-02, -1.50604080e-02, -1.32848814e-01,\n",
       "          1.60886034e-01,  3.31191510e-01,  1.50362715e-01,\n",
       "         -3.37562561e-02, -2.82825410e-01, -1.96428776e-01,\n",
       "          2.23382607e-01, -5.96768484e-02,  1.53935710e-02,\n",
       "         -2.28989050e-01, -7.42953569e-02,  2.30342522e-01,\n",
       "          7.68296942e-02,  1.34737045e-02, -1.32661939e-01,\n",
       "          2.36685835e-02,  2.61563778e-01,  1.38941854e-01,\n",
       "          6.69113398e-02, -5.91301173e-02,  2.83082306e-01,\n",
       "          1.04328021e-02,  2.25828975e-01,  9.52880159e-02,\n",
       "          2.42456585e-01,  1.05253728e-02,  7.37253502e-02,\n",
       "          8.52136388e-02, -1.81840166e-01,  6.74012525e-04,\n",
       "         -1.59818649e-01, -1.16286255e-01, -8.95565748e-02,\n",
       "         -3.35160568e-02,  5.25046214e-02],\n",
       "        [-1.15326454e-03,  1.40958413e-01,  7.33345374e-02,\n",
       "          2.70687342e-02, -3.72735634e-02, -3.84248979e-02,\n",
       "         -1.09806627e-01, -4.04956907e-01,  1.57948866e-01,\n",
       "          2.07279876e-01,  2.14710161e-01, -1.57035932e-01,\n",
       "         -3.23792219e-01,  3.15371640e-02, -1.54774472e-01,\n",
       "          2.33657598e-01, -1.63901612e-01, -3.89676213e-01,\n",
       "          1.71036676e-01,  3.35468687e-02,  1.12127915e-01,\n",
       "         -7.60454163e-02, -3.70618999e-01,  1.01323865e-01,\n",
       "         -3.40771908e-03, -2.12661654e-01, -9.86684337e-02,\n",
       "          1.12606369e-01,  5.29523529e-02,  1.13737091e-01,\n",
       "         -2.02777117e-01,  1.50520448e-02, -1.51387557e-01,\n",
       "         -1.22631140e-01,  4.72104214e-02,  3.51222247e-01,\n",
       "         -1.65231943e-01,  2.34892339e-01,  1.07201897e-01,\n",
       "          3.13871689e-02,  1.32264227e-01, -2.80727804e-01,\n",
       "          1.64457023e-01, -1.55327037e-01, -3.07159293e-02,\n",
       "         -1.28224716e-01, -8.46576989e-02,  1.29369169e-03,\n",
       "          3.21908928e-02,  1.10266447e-01],\n",
       "        [-1.65297359e-01, -4.93476152e-01, -3.74075979e-01,\n",
       "         -1.61590710e-01,  4.93627600e-02,  9.17891935e-02,\n",
       "          1.98574096e-01,  4.58476506e-02,  1.04114220e-01,\n",
       "          2.85808258e-02, -1.37656793e-01,  4.33975756e-02,\n",
       "         -5.01313061e-02,  2.23760858e-01,  2.67816067e-01,\n",
       "          5.68411611e-02,  1.24855421e-01,  1.80662185e-01,\n",
       "          1.19944960e-02, -1.19749427e-01,  7.74386674e-02,\n",
       "         -8.89447555e-02, -3.67632210e-01, -4.52572182e-02,\n",
       "         -8.79938006e-02, -1.05921112e-01,  1.95444062e-01,\n",
       "         -2.50155777e-01,  3.06867678e-02, -1.43980011e-01,\n",
       "          3.23003948e-01,  2.17870563e-01, -8.84651840e-02,\n",
       "         -3.30626577e-01, -1.49875656e-01, -1.17194220e-01,\n",
       "          1.93659604e-01, -2.37518176e-02,  1.84016258e-01,\n",
       "          6.66077510e-02,  2.30632707e-01, -2.71660984e-01,\n",
       "         -3.27371389e-01, -1.45841181e-01, -2.31160223e-02,\n",
       "          1.75116107e-01,  6.15703911e-02, -2.96301752e-01,\n",
       "         -1.64621964e-01,  3.64953369e-01],\n",
       "        [-3.59876007e-02, -1.30203053e-01,  2.80587133e-02,\n",
       "         -1.97843760e-01,  9.64333043e-02, -1.89312249e-01,\n",
       "          1.02637194e-01,  1.38065934e-01, -2.61340678e-01,\n",
       "         -9.08830389e-02,  1.64246261e-01, -2.71908641e-01,\n",
       "          2.98631042e-02,  6.30930588e-02,  1.80577755e-01,\n",
       "          1.75641671e-01, -7.28336573e-02, -1.13968648e-01,\n",
       "         -2.08228976e-01, -6.21166267e-02, -6.72942214e-03,\n",
       "          2.39013493e-01,  3.94722559e-02, -2.99634766e-02,\n",
       "          1.71182558e-01,  1.21278636e-01, -1.98877513e-01,\n",
       "         -1.70386314e-01,  1.01060316e-01, -1.15730450e-01,\n",
       "          2.39375263e-01,  8.87387991e-02, -5.10871410e-03,\n",
       "          3.78601775e-02, -4.25005741e-02, -3.76922339e-02,\n",
       "          1.53184280e-01,  1.42779633e-01,  3.98657564e-03,\n",
       "          2.31430247e-01, -9.09573585e-02, -1.01515159e-01,\n",
       "          3.06916744e-01,  4.03624699e-02, -2.72954255e-01,\n",
       "         -2.75094271e-01, -1.80032905e-02,  1.30077675e-01,\n",
       "          1.06384866e-01, -3.71808946e-01],\n",
       "        [ 8.92016068e-02,  1.37810990e-01,  5.32862879e-02,\n",
       "          7.00610504e-02,  2.03241762e-02,  1.82305470e-01,\n",
       "         -1.23097613e-01, -3.95779729e-01,  2.46658266e-01,\n",
       "         -2.78271586e-01, -4.48871665e-02,  2.26115748e-01,\n",
       "          2.08804235e-01, -1.96783483e-01,  1.65890213e-02,\n",
       "         -1.68697983e-01,  1.36156961e-01,  5.83840869e-02,\n",
       "         -1.12457596e-01,  3.50908846e-01,  3.05414051e-01,\n",
       "         -3.47082436e-01, -1.76266283e-01,  9.04897526e-02,\n",
       "          3.55605572e-01,  1.89794019e-01,  2.84389853e-01,\n",
       "          1.43318549e-01,  1.35271460e-01, -3.95610463e-03,\n",
       "         -1.68315873e-01,  2.66759600e-02, -8.19582045e-02,\n",
       "          1.97475150e-01, -1.27591103e-01,  9.74756107e-02,\n",
       "         -4.96836826e-02,  1.53557777e-01,  2.14368552e-01,\n",
       "          1.14309587e-01,  3.49750631e-02,  1.03399664e-01,\n",
       "          8.10623094e-02,  1.95784599e-01,  3.93408507e-01,\n",
       "          2.07030877e-01,  1.74094975e-01, -2.73711622e-01,\n",
       "          5.53028565e-03,  2.21217528e-01],\n",
       "        [-1.06179215e-01, -3.17897677e-01,  5.29141985e-02,\n",
       "         -1.63119465e-01, -4.60297763e-01, -9.93945450e-02,\n",
       "         -2.52037257e-01,  5.89494705e-02,  2.26562351e-01,\n",
       "         -1.57997967e-03,  5.48300408e-02, -4.41513836e-01,\n",
       "         -3.50467443e-01,  3.00824702e-01, -1.48471490e-01,\n",
       "         -7.24418461e-01, -7.13142574e-01,  1.98965296e-01,\n",
       "          7.50826418e-01, -5.43222129e-01, -3.62884104e-01,\n",
       "         -1.34685457e-01, -6.55326322e-02,  1.01264529e-01,\n",
       "         -4.58069801e-01, -5.25589526e-01, -3.43203247e-01,\n",
       "          1.52094036e-01,  1.23897240e-01,  4.08555090e-01,\n",
       "          1.78272128e-01, -1.59359515e-01,  4.16816533e-01,\n",
       "          1.26736537e-01,  3.77733707e-02,  3.30071062e-01,\n",
       "         -1.05926824e+00, -3.94405201e-02,  1.25375271e-01,\n",
       "          2.53577679e-01, -1.91066504e-01, -1.35355115e-01,\n",
       "         -5.17278491e-03, -9.30923596e-02,  3.59010190e-01,\n",
       "         -4.15622354e-01,  1.17633307e+00, -1.02373827e+00,\n",
       "          3.79683226e-01,  1.75833479e-01],\n",
       "        [-4.38569114e-02,  4.03477371e-01,  1.60517439e-01,\n",
       "         -1.67970255e-01, -2.15044349e-01,  2.12968647e-01,\n",
       "          7.49283955e-02,  1.19539611e-01,  8.53366852e-02,\n",
       "          1.81806117e-01,  1.96902767e-01,  1.57667071e-01,\n",
       "          1.25833616e-01,  4.96730357e-02, -2.07657143e-01,\n",
       "          4.30763327e-02,  3.52034241e-01, -5.58405817e-02,\n",
       "          7.60824308e-02, -8.06562066e-01,  1.46590844e-01,\n",
       "          1.59468934e-01, -5.51406026e-01,  3.19187701e-01,\n",
       "          1.78781599e-01, -2.68169761e-01, -1.86941937e-01,\n",
       "         -6.61846161e-01,  2.54272610e-01,  4.12155390e-02,\n",
       "         -1.28246248e-01,  3.18291247e-01,  3.23033869e-01,\n",
       "         -1.19959734e-01, -1.59174517e-01, -8.83273929e-02,\n",
       "         -1.87742077e-02, -3.57947499e-02,  2.45749578e-01,\n",
       "         -1.83527827e-01,  2.06553012e-01, -9.10735801e-02,\n",
       "         -1.98622406e-01, -5.24738789e-01,  4.11079437e-01,\n",
       "          9.19682309e-02, -1.05847515e-01, -1.74697593e-01,\n",
       "          3.53316106e-02, -5.15506864e-01],\n",
       "        [-8.45167637e-01, -4.90271226e-02, -7.79727638e-01,\n",
       "         -5.74111581e-01, -6.75274730e-01,  4.27837729e-01,\n",
       "         -1.96804717e-01, -2.03707606e-01, -8.74838114e-01,\n",
       "          2.90383935e-01, -1.99731037e-01, -6.71972215e-01,\n",
       "         -7.05913603e-01,  4.27385420e-01,  1.55701697e-01,\n",
       "         -2.86866635e-01,  2.63694137e-01, -6.69765770e-01,\n",
       "          3.22576106e-01,  1.53855896e-02, -5.86932003e-01,\n",
       "          2.69856632e-01, -4.13178086e-01,  9.45832253e-01,\n",
       "         -2.40848705e-01, -8.38995650e-02, -2.81348020e-01,\n",
       "         -9.19859827e-01, -8.15669954e-01,  4.73655537e-02,\n",
       "          3.11379939e-01, -1.01295245e+00,  8.30139756e-01,\n",
       "         -2.23889470e-01,  2.23271400e-01,  8.61048102e-01,\n",
       "         -3.32570344e-01,  5.85694969e-01,  9.20760632e-01,\n",
       "          4.32880223e-01, -4.60580409e-01,  8.68620947e-02,\n",
       "         -1.17756471e-01, -2.11300477e-01, -4.77168411e-01,\n",
       "         -6.91150665e-01,  2.48756990e-01,  1.30617097e-01,\n",
       "          1.93336457e-01, -7.71786392e-01],\n",
       "        [-1.24187894e-01,  1.53250322e-01, -2.22704172e-01,\n",
       "         -5.37676454e-01,  6.46167696e-02,  1.00688480e-01,\n",
       "          2.13547245e-01,  1.37204424e-01,  2.80419260e-01,\n",
       "          3.14195663e-01, -2.95445055e-01, -4.20671046e-01,\n",
       "         -2.12955624e-01,  1.69935986e-01, -2.24079818e-01,\n",
       "         -1.71813946e-02, -1.32757127e-01,  2.91134641e-02,\n",
       "          6.84206784e-02, -1.25318989e-01,  2.29552820e-01,\n",
       "          9.26664025e-02,  8.30918476e-02,  2.55690003e-03,\n",
       "          1.50419876e-01, -3.64924878e-01,  1.25954732e-01,\n",
       "          3.60522360e-01,  3.96234356e-02, -3.69266458e-02,\n",
       "         -7.99834207e-02, -2.75227219e-01,  3.64018053e-01,\n",
       "         -2.54400462e-01, -3.82962450e-02,  1.53976411e-01,\n",
       "          4.01050806e-01, -2.89413512e-01,  1.84237525e-01,\n",
       "         -3.19998711e-02, -4.68666591e-02, -1.06933556e-01,\n",
       "         -2.11865231e-01, -7.91701823e-02,  3.14896911e-01,\n",
       "         -3.17986429e-01,  1.04031246e-03,  1.64690167e-01,\n",
       "          2.11215004e-01,  1.15542173e-01],\n",
       "        [-1.52697653e-01,  1.35515958e-01,  2.61976212e-01,\n",
       "          3.10674906e-01, -1.25776559e-01,  1.61179438e-01,\n",
       "         -8.43572393e-02, -1.87759787e-01,  8.15051608e-03,\n",
       "         -2.43471712e-01, -9.00355577e-02,  6.39745146e-02,\n",
       "         -2.73957197e-02, -3.73980850e-02, -2.24532664e-01,\n",
       "         -2.06559166e-01, -2.78268039e-01, -9.70337763e-02,\n",
       "         -2.17686132e-01,  2.46047258e-01, -2.09688306e-01,\n",
       "         -3.85493562e-02,  3.62352058e-02,  2.54905730e-01,\n",
       "          2.37924114e-01,  1.39741555e-01,  2.15747625e-01,\n",
       "          8.98950249e-02,  2.30968639e-01,  4.74368595e-02,\n",
       "          1.56619012e-01, -2.59913385e-01, -1.75044179e-01,\n",
       "         -1.55733138e-01,  1.51230663e-01,  1.25680774e-01,\n",
       "          1.20257214e-01,  1.76675513e-01,  5.53210974e-02,\n",
       "          8.75060111e-02,  2.16610581e-01, -3.18948063e-03,\n",
       "          3.00863814e-02,  1.06827267e-01, -1.35410666e-01,\n",
       "          3.48425657e-02, -1.29592478e-01, -1.42666772e-01,\n",
       "          8.46333206e-02, -8.65105912e-02],\n",
       "        [-3.02350670e-01, -2.17246488e-01, -1.19274352e-02,\n",
       "          3.92568856e-01,  1.73270792e-01,  8.33428800e-02,\n",
       "          2.56282955e-01, -3.66391540e-02, -2.42301121e-01,\n",
       "          2.03645974e-01, -2.49304369e-01,  1.56437010e-01,\n",
       "          2.80101448e-01, -1.19612694e-01,  1.26213521e-01,\n",
       "         -2.28467304e-02,  5.75226285e-02, -2.17099726e-01,\n",
       "         -1.14520594e-01,  4.06616986e-01,  2.98351943e-01,\n",
       "          1.54262155e-01, -3.60534973e-02,  6.29939586e-02,\n",
       "         -1.79287598e-01,  8.54770765e-02, -1.89941108e-01,\n",
       "         -7.21891597e-02, -2.12475747e-01, -1.37330875e-01,\n",
       "          2.42382549e-02,  2.81719983e-01,  8.11149925e-02,\n",
       "         -9.36997384e-02, -9.41302031e-02,  3.24180722e-01,\n",
       "          1.38191700e-01, -1.49783537e-01, -8.91436487e-02,\n",
       "         -2.03064546e-01,  7.38547072e-02, -2.99737990e-01,\n",
       "         -2.90968210e-01,  1.56039506e-01, -2.96443701e-01,\n",
       "          1.96310833e-01, -3.83066505e-01,  3.14890951e-01,\n",
       "         -2.65818000e-01,  1.47337064e-01],\n",
       "        [ 3.89957651e-02, -2.37238899e-01, -1.82180673e-01,\n",
       "          3.28544021e-01,  2.50360668e-01,  2.66237170e-01,\n",
       "         -3.52953047e-01, -3.24714661e-01, -1.25182152e-01,\n",
       "          3.69219691e-01, -2.96460152e-01,  2.60759115e-01,\n",
       "         -3.57618295e-02,  5.51231563e-01,  2.79186457e-01,\n",
       "         -4.29031491e-01, -3.26944701e-02, -1.96009725e-01,\n",
       "          1.88105553e-01, -1.40163332e-01, -1.98868290e-01,\n",
       "         -6.60940036e-02,  3.80856879e-02,  9.67012942e-02,\n",
       "         -1.83343843e-01,  2.44084280e-02, -2.61525929e-01,\n",
       "         -3.77425887e-02, -4.07712877e-01,  4.73365523e-02,\n",
       "          2.86767930e-01,  2.06568226e-01,  2.30679855e-01,\n",
       "         -2.07351387e-01, -6.17332757e-02,  2.87816912e-01,\n",
       "         -4.50491160e-02,  4.72484112e-01,  3.38469863e-01,\n",
       "          2.60895997e-01,  2.74625093e-01,  7.16895163e-02,\n",
       "          1.55633986e-01,  7.33178779e-02, -4.16514635e-01,\n",
       "         -1.60211369e-01,  2.37636700e-01, -1.05144471e-01,\n",
       "          1.73046857e-01, -6.21132739e-02],\n",
       "        [ 4.27838653e-01, -8.71297419e-02,  4.09167200e-01,\n",
       "          8.83903280e-02,  1.36366151e-02, -2.34538466e-01,\n",
       "         -2.30815023e-01, -3.63350399e-02,  4.58525896e-01,\n",
       "         -4.31434602e-01, -8.26330855e-02,  3.11995856e-02,\n",
       "         -5.83220720e-02, -3.32133055e-01, -5.67130923e-01,\n",
       "         -4.09574479e-01, -2.37651974e-01,  3.06016922e-01,\n",
       "         -9.30585433e-03,  7.52543733e-02, -3.88224125e-01,\n",
       "         -4.18425649e-01,  1.77721843e-01, -3.76096427e-01,\n",
       "         -2.68949717e-01, -4.05978799e-01,  5.70346974e-02,\n",
       "          1.77671954e-01, -4.11263146e-02, -8.56439114e-01,\n",
       "         -1.49700001e-01,  2.34057754e-01, -3.57449092e-02,\n",
       "         -1.07740872e-01, -2.41298648e-03, -3.93026292e-01,\n",
       "         -3.72572750e-01, -6.44572616e-01,  9.92844403e-02,\n",
       "         -3.78077984e-01, -1.56160668e-02, -1.02564082e-01,\n",
       "          3.08661252e-01, -2.14511976e-01,  1.31454080e-01,\n",
       "          3.17087948e-01, -6.48451090e-01, -3.26523036e-01,\n",
       "          7.54223019e-02, -5.08367084e-02],\n",
       "        [ 8.19583461e-02,  1.69241339e-01,  1.26596004e-01,\n",
       "         -1.54211357e-01, -3.40416163e-01, -1.30831659e-01,\n",
       "         -2.81167716e-01, -3.86572242e-01, -3.72371227e-02,\n",
       "         -6.59375712e-02, -2.53446192e-01, -3.81581932e-02,\n",
       "          2.23740175e-01,  1.61491007e-01, -2.58770257e-01,\n",
       "          1.09202057e-01,  2.87298672e-03,  2.01842561e-01,\n",
       "         -5.36115766e-02,  1.40463829e-01, -4.64066342e-02,\n",
       "         -1.41841292e-01,  2.30167776e-01,  1.18819550e-01,\n",
       "          3.17410529e-01, -3.39945182e-02, -1.10118218e-01,\n",
       "         -2.16529984e-02,  1.64597228e-01, -1.33195175e-02,\n",
       "         -6.88608289e-02,  6.53964132e-02,  3.13889496e-02,\n",
       "          1.06786154e-01, -2.49629691e-01,  1.24318190e-01,\n",
       "          2.61431728e-02,  1.51657447e-01,  1.49589619e-02,\n",
       "         -2.60506034e-01, -2.85459161e-01,  1.13436743e-03,\n",
       "          9.26343352e-02,  5.21828644e-02,  4.60948832e-02,\n",
       "          2.37462983e-01,  1.50666470e-02,  2.67523043e-02,\n",
       "         -1.91588908e-01,  1.45732373e-01],\n",
       "        [-3.52912657e-02, -2.63031095e-01,  1.97510779e-01,\n",
       "         -1.88091829e-01, -3.74298245e-01, -8.04589242e-02,\n",
       "         -4.23345655e-01, -4.10006732e-01,  2.61674672e-02,\n",
       "         -1.69509590e-01, -1.20362803e-01,  2.11891204e-01,\n",
       "          2.08155066e-01, -9.56956223e-02,  1.78981423e-01,\n",
       "         -1.37057617e-01, -3.16319652e-02,  2.03869566e-01,\n",
       "         -2.31210720e-02,  2.34020948e-01, -2.01193858e-02,\n",
       "         -2.49494743e-02,  2.96160340e-01,  3.93547341e-02,\n",
       "          1.67379975e-02, -5.03131211e-01, -3.17510843e-01,\n",
       "         -5.07766865e-02, -1.55505225e-01,  2.27422826e-02,\n",
       "          8.77784640e-02, -5.08843213e-02, -8.60993750e-03,\n",
       "          4.28549014e-02, -2.79232770e-01,  2.32534841e-01,\n",
       "          6.57566264e-02,  5.66716194e-02,  1.32103562e-01,\n",
       "         -5.76021038e-02, -1.01734363e-01, -2.59666204e-01,\n",
       "         -2.64397800e-01,  9.07599032e-02,  3.05216536e-02,\n",
       "          2.42712960e-01,  3.10461354e-02, -4.77432124e-02,\n",
       "         -7.62634501e-02,  9.66683328e-02],\n",
       "        [ 1.24548197e-01,  1.70239240e-01, -1.80235773e-01,\n",
       "         -9.13516507e-02,  1.89374849e-01,  2.19717249e-01,\n",
       "          2.09395051e-01,  8.18166137e-03, -9.51158702e-02,\n",
       "          2.30847880e-01, -1.01544082e-01, -9.92417336e-02,\n",
       "          2.05901131e-01, -3.45435590e-02,  1.17274851e-01,\n",
       "          1.63179383e-01, -1.40650153e-01,  1.27927244e-01,\n",
       "          1.64377660e-01,  1.02631271e-01, -1.31760746e-01,\n",
       "          8.62485096e-02,  2.24940613e-01,  1.44559950e-01,\n",
       "         -2.52656847e-01,  1.31331131e-01, -1.45302668e-01,\n",
       "         -1.18154116e-01, -1.31635085e-01,  7.92425722e-02,\n",
       "          1.60544187e-01,  1.63259376e-02, -3.43108550e-02,\n",
       "         -1.88776135e-01, -2.58476734e-01,  4.95744944e-02,\n",
       "         -8.93432833e-03, -7.36477375e-02,  3.26133370e-01,\n",
       "          2.19916599e-03, -6.32272959e-02, -5.18796295e-02,\n",
       "          2.22027019e-01, -1.81554914e-01, -2.19031155e-01,\n",
       "         -2.43029237e-01,  1.99726410e-03, -4.21727225e-02,\n",
       "          2.11367663e-02, -1.33545130e-01],\n",
       "        [-2.52790093e-01, -1.09295115e-01, -1.32055894e-01,\n",
       "          1.91596732e-01,  4.08808291e-02, -2.13328809e-01,\n",
       "         -2.91574359e-01,  1.47448927e-01, -1.70008034e-01,\n",
       "          3.37465495e-01, -1.08418055e-01,  2.19517976e-01,\n",
       "         -4.33255136e-01, -1.37296677e-01,  1.03213996e-01,\n",
       "          1.59564972e-01,  4.01656479e-02, -2.90098757e-01,\n",
       "          1.42138034e-01, -1.43206686e-01,  1.57169495e-02,\n",
       "          8.65791664e-02,  2.27519318e-01, -2.08278596e-01,\n",
       "         -7.13639781e-02, -1.05178937e-01, -3.14976722e-01,\n",
       "          3.05627994e-02, -3.25357611e-03,  9.22854245e-03,\n",
       "          2.13380352e-01, -2.00644255e-01, -1.14536211e-01,\n",
       "         -1.91276476e-01, -7.56338588e-04, -9.39195678e-02,\n",
       "         -9.45832059e-02, -6.51236475e-02, -4.24157418e-02,\n",
       "          2.63328254e-01, -3.87331754e-01,  1.40041053e-01,\n",
       "         -2.00736314e-01,  2.69274294e-01, -6.11840971e-02,\n",
       "          2.03854516e-01, -5.79484217e-02,  2.12666243e-01,\n",
       "          1.09501883e-01,  2.77578142e-02],\n",
       "        [ 3.59619319e-01, -7.78527781e-02,  1.35020558e-02,\n",
       "         -6.71003088e-02,  2.17909649e-01, -3.64211909e-02,\n",
       "          1.68522254e-01, -1.89959541e-01,  1.32671073e-01,\n",
       "         -1.42846787e-02,  2.20919415e-01,  1.47609487e-01,\n",
       "          1.72494337e-01,  2.60608196e-01,  3.44589293e-01,\n",
       "         -1.51967525e-01,  1.01489246e-01, -1.89605013e-01,\n",
       "         -6.04906976e-02, -4.19209957e-01, -2.15932205e-01,\n",
       "         -1.44032494e-03, -3.30866128e-01, -1.45321647e-02,\n",
       "         -3.51996161e-02,  1.92555517e-01, -6.91092312e-02,\n",
       "         -8.98299143e-02,  1.91712119e-02,  5.09083688e-01,\n",
       "         -3.77187878e-01, -8.58670995e-02, -3.17335099e-01,\n",
       "          1.02336176e-01, -1.58157676e-01, -2.70127654e-01,\n",
       "         -2.64824063e-01,  1.91925436e-01, -1.98529005e-01,\n",
       "         -4.99361195e-02, -4.06207368e-02, -9.09485593e-02,\n",
       "         -1.37348682e-01, -8.94737720e-01,  2.51095533e-01,\n",
       "          2.45557666e-01,  3.13939154e-01,  3.99428576e-01,\n",
       "         -1.04821377e-01,  1.66233018e-01],\n",
       "        [ 4.31225374e-02, -1.03812732e-01,  6.70941323e-02,\n",
       "         -2.20529556e-01, -1.70392171e-01, -2.16128379e-01,\n",
       "          7.32309893e-02,  1.04086071e-01, -4.93322052e-02,\n",
       "          3.87929217e-03, -1.64180011e-01,  1.52164981e-01,\n",
       "          6.96261823e-02, -2.68794864e-01, -3.45289595e-02,\n",
       "          3.23412091e-01,  2.55482495e-01,  5.85699379e-02,\n",
       "         -5.36467209e-02, -2.90945675e-02,  3.59823823e-01,\n",
       "          8.00642520e-02,  6.93185925e-02, -4.93344627e-02,\n",
       "         -5.64498305e-02,  1.53818160e-01,  1.19869232e-01,\n",
       "          2.21635759e-01,  1.74413398e-01,  8.63005780e-03,\n",
       "         -2.98062593e-01,  6.05532750e-02, -1.13025717e-01,\n",
       "         -2.14249790e-01, -1.75938427e-01, -1.60916612e-01,\n",
       "          1.66036621e-01, -7.10271895e-02,  8.56137052e-02,\n",
       "         -1.22722536e-01, -6.76708808e-03, -1.75374329e-01,\n",
       "         -5.21374822e-01, -7.16969371e-01,  5.16535752e-02,\n",
       "          2.96808690e-01, -1.47466034e-01, -9.83252525e-02,\n",
       "          2.50985604e-02, -7.23047182e-02],\n",
       "        [-3.91840674e-02,  1.92811027e-01,  9.23364386e-02,\n",
       "         -1.02235153e-01,  6.40290007e-02, -1.97463885e-01,\n",
       "          2.14483902e-01,  8.87786821e-02,  1.47281975e-01,\n",
       "         -1.36094272e-01,  2.95308113e-01,  2.61316802e-02,\n",
       "          7.36157075e-02, -1.81862846e-01,  2.73307234e-01,\n",
       "          1.44278392e-01,  1.52776018e-01, -5.55586489e-03,\n",
       "         -1.72876462e-01,  5.70216551e-02,  1.28096342e-01,\n",
       "         -3.57777141e-02, -1.13198534e-01, -5.13082445e-02,\n",
       "          1.89953730e-01,  1.84390813e-01,  3.46667141e-01,\n",
       "          1.75936460e-01,  5.18491082e-02, -2.65560094e-02,\n",
       "         -1.23906136e-01,  1.65558115e-01,  1.45284692e-02,\n",
       "         -1.49727538e-01, -1.82070043e-02, -2.56128758e-01,\n",
       "          7.55014196e-02,  9.05368850e-02, -1.78554818e-01,\n",
       "         -5.38966060e-03,  5.99010102e-03,  1.53481990e-01,\n",
       "          3.77907038e-01,  3.07402283e-01,  1.69548929e-01,\n",
       "          1.53800488e-01, -1.48446515e-01, -3.75161991e-02,\n",
       "          1.48817092e-01,  1.74677283e-01]], dtype=float32),\n",
       " array([ 0.1217435 , -0.04104857,  0.07326482,  0.05406783,  0.13679281,\n",
       "        -0.11534952,  0.09400832, -0.06577292,  0.08066751, -0.09161229,\n",
       "        -0.03202192,  0.09395017,  0.04407151, -0.07950126, -0.00449014,\n",
       "         0.10061954,  0.08077189,  0.04589732, -0.12965912,  0.06372233,\n",
       "         0.13365489, -0.07120679,  0.02937469, -0.11315471,  0.08670099,\n",
       "         0.02745141,  0.09976741,  0.063767  ,  0.10479373,  0.02841362,\n",
       "        -0.10568506,  0.08856332, -0.1129059 , -0.04814797, -0.04498071,\n",
       "        -0.06213985,  0.17317893, -0.05239496, -0.10768174, -0.11578973,\n",
       "        -0.03356821, -0.09114489,  0.04499256,  0.02241991,  0.13519946,\n",
       "         0.0778393 , -0.03182648,  0.02686472, -0.1073872 ,  0.01267984],\n",
       "       dtype=float32),\n",
       " array([[ 0.27695373, -0.14276175,  0.12343242, ...,  0.19266227,\n",
       "          0.19504565,  0.26994532],\n",
       "        [ 0.30308282,  0.12835677, -0.26787144, ..., -0.18541922,\n",
       "         -0.10736088,  0.11367979],\n",
       "        [ 0.14551646,  0.07669839, -0.00593039, ...,  0.23559332,\n",
       "         -0.12105591,  0.06370343],\n",
       "        ...,\n",
       "        [ 0.18138799,  0.16097683, -0.03283703, ..., -0.02701626,\n",
       "          0.02400365,  0.3006405 ],\n",
       "        [-0.0022917 , -0.21217552,  0.2895291 , ..., -0.04596928,\n",
       "          0.11870763,  0.01209045],\n",
       "        [-0.3562687 , -0.06109105,  0.16020878, ...,  0.06755744,\n",
       "          0.22624472,  0.35292768]], dtype=float32),\n",
       " array([-0.02304079,  0.06127382,  0.16148692, -0.04735388, -0.05657044,\n",
       "         0.11438184, -0.05220592,  0.02180544,  0.11478064,  0.00659696,\n",
       "         0.07959879, -0.11944515,  0.01692261, -0.07822746, -0.06208303,\n",
       "        -0.06281779, -0.02099494,  0.11404265, -0.04983673,  0.04362798,\n",
       "         0.15939806,  0.10530028, -0.05226392,  0.11773209,  0.14455107],\n",
       "       dtype=float32),\n",
       " array([[ 0.05339495,  0.19844039, -0.15527669,  0.04354784, -0.7473176 ],\n",
       "        [ 0.07597095,  0.40373   ,  0.26013982, -0.54831165,  0.3243999 ],\n",
       "        [-0.08929262,  0.3734691 , -0.30552295,  0.39594692,  0.25473124],\n",
       "        [-0.4752589 , -0.1877197 , -0.2250056 ,  0.61763394, -0.32805347],\n",
       "        [-0.32067955, -0.38600606,  0.43632036,  0.18385158, -0.3023591 ],\n",
       "        [ 0.17339139,  0.45500183,  0.06397218, -0.6425593 ,  0.22977827],\n",
       "        [-0.4048071 , -0.3072671 ,  0.23885107, -0.1185088 ,  0.34268665],\n",
       "        [-0.41610795,  0.16355574,  0.17983198, -0.18690355,  0.4730797 ],\n",
       "        [-0.48762614,  0.05479231, -0.3476422 , -0.16746494, -0.33408827],\n",
       "        [ 0.08562401,  0.15938058, -0.31946445, -0.17339295,  0.21757282],\n",
       "        [-0.4201108 ,  0.14662324, -0.138989  ,  0.0641906 ,  0.1779952 ],\n",
       "        [-0.2498475 , -0.0877188 , -0.11405754,  0.32699814,  0.25675184],\n",
       "        [-0.44022045,  0.38400546,  0.07584196, -0.20960267,  0.07149211],\n",
       "        [-0.02127292, -0.08608657, -0.43883678, -0.0980652 , -0.34170786],\n",
       "        [ 0.3695147 , -0.33109722, -0.2958404 ,  0.55223376,  0.21277077],\n",
       "        [-0.3603456 ,  0.01140267, -0.1925261 ,  0.0141554 , -0.18531309],\n",
       "        [ 0.082299  , -0.34424865, -0.01776549,  0.59078556, -0.66006696],\n",
       "        [ 0.13940005,  0.13886818, -0.34901914,  0.03916387,  0.20661615],\n",
       "        [ 0.00548485,  0.48661834, -0.19909756, -0.41650304, -0.21485993],\n",
       "        [ 0.1870706 ,  0.35461718,  0.00244755,  0.25526544,  0.37558994],\n",
       "        [-0.367926  ,  0.30754942,  0.04021239, -0.11093042, -0.4398306 ],\n",
       "        [ 0.09430989,  0.1474688 , -0.42392242,  0.26730016, -0.32892004],\n",
       "        [ 0.18630815, -0.21002859, -0.43881395,  0.10096372,  0.35829067],\n",
       "        [-0.11437885,  0.22862427, -0.12193748, -0.06802924, -0.16809948],\n",
       "        [-0.01208816,  0.18765327, -0.16926938, -0.28487954,  0.02405624]],\n",
       "       dtype=float32),\n",
       " array([-0.06704997,  0.1592909 ,  0.        ,  0.0912152 , -0.08766498],\n",
       "       dtype=float32),\n",
       " array([[ 0.62119853, -0.74663645],\n",
       "        [ 0.10239518, -0.80674905],\n",
       "        [-0.6698717 , -0.48422864],\n",
       "        [ 0.5078208 ,  1.1457576 ],\n",
       "        [ 0.59966165,  0.02540366]], dtype=float32),\n",
       " array([-0.05010869,  0.05010987], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5362094  0.4637906 ]\n",
      " [0.8539383  0.14606167]\n",
      " [0.7255047  0.27449533]\n",
      " ...\n",
      " [0.625373   0.37462696]\n",
      " [0.5435859  0.45641413]\n",
      " [0.8088053  0.19119473]]\n",
      "[0 1 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(predictions)\n",
    "print(np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      " [[1352  453]\n",
      " [ 777 1062]]\n"
     ]
    }
   ],
   "source": [
    "rounded = np.rint(predictions)\n",
    "\n",
    "con_mat = tf.confusion_matrix(labels=np.argmax(y_test, axis=1),predictions=np.argmax(predictions, axis=1), num_classes=2, dtype=tf.int32, name=None)\n",
    "\n",
    "with tf.Session():\n",
    "   print('Confusion Matrix: \\n\\n', tf.Tensor.eval(con_mat,feed_dict=None, session=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfoldcrossvalidation(alldata, split_size=5, optimizer=\"adam\", epochs=10, batch_size=32, sample_frac=1):\n",
    "    alldata = pd.DataFrame(alldata).sample(frac=sample_frac) #Shuffles Data when frac=1\n",
    "    kf = KFold(n_splits=split_size)\n",
    "    average_loss, average_acc, average_auc = (0,0,0)\n",
    "    index = 1\n",
    "    print(optimizer, \"test\")\n",
    "    for train_index, test_index in kf.split(alldata):\n",
    "        x_train = alldata.iloc[:,0:-1].values[train_index]\n",
    "        y_train = to_categorical(pd.to_numeric(alldata.iloc[:,-1], downcast='integer').values[train_index])\n",
    "        x_test = alldata.iloc[:,0:-1].values[test_index]\n",
    "        y_test = to_categorical(pd.to_numeric(alldata.iloc[:,-1], downcast='integer').values[test_index])\n",
    "        model = model_creation(optimizer=optimizer)\n",
    "        model.fit(x_train, y_train, epochs=epochs, verbose=0)\n",
    "        model_loss, model_acc, model_auc = model.evaluate(x_test, y_test, verbose=0)\n",
    "        average_loss += model_loss/split_size\n",
    "        average_acc += model_acc/split_size\n",
    "        average_auc += model_auc/split_size\n",
    "        print(\"Split\", index,\"Accuracy:\",\"%.3f\" % model_acc)\n",
    "        index += 1\n",
    "    print(\"Average Model Loss:\", \"%.3f\" % average_loss)\n",
    "    print(\"Average Model Accuracy:\", \"%.3f\" % average_acc)\n",
    "    print(\"Average Model AUC:\", \"%.3f\" % average_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldcrossvalidation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 Accuracy: 0.671\n",
      "Split 2 Accuracy: 0.661\n",
      "Split 3 Accuracy: 0.642\n",
      "Split 4 Accuracy: 0.668\n",
      "Split 5 Accuracy: 0.648\n",
      "Split 6 Accuracy: 0.636\n",
      "Split 7 Accuracy: 0.678\n",
      "Split 8 Accuracy: 0.660\n",
      "Split 9 Accuracy: 0.662\n",
      "Split 10 Accuracy: 0.672\n",
      "Average Model Loss: 0.612\n",
      "Average Model Accuracy: 0.660\n",
      "Average Model AUC: 0.716\n"
     ]
    }
   ],
   "source": [
    "kfoldcrossvalidation(data, split_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 Accuracy: 0.639\n",
      "Split 2 Accuracy: 0.664\n",
      "Split 3 Accuracy: 0.686\n",
      "Split 4 Accuracy: 0.673\n",
      "Split 5 Accuracy: 0.638\n",
      "Split 6 Accuracy: 0.664\n",
      "Split 7 Accuracy: 0.680\n",
      "Split 8 Accuracy: 0.653\n",
      "Split 9 Accuracy: 0.627\n",
      "Split 10 Accuracy: 0.675\n",
      "Average Model Loss: 0.585\n",
      "Average Model Accuracy: 0.660\n",
      "Average Model AUC: 0.729\n"
     ]
    }
   ],
   "source": [
    "kfoldcrossvalidation(data, split_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 Accuracy: 0.630\n",
      "Split 2 Accuracy: 0.632\n",
      "Split 3 Accuracy: 0.644\n",
      "Split 4 Accuracy: 0.631\n",
      "Split 5 Accuracy: 0.645\n",
      "Split 6 Accuracy: 0.645\n",
      "Split 7 Accuracy: 0.630\n",
      "Split 8 Accuracy: 0.632\n",
      "Split 9 Accuracy: 0.650\n",
      "Split 10 Accuracy: 0.636\n",
      "Average Model Loss: 0.627\n",
      "Average Model Accuracy: 0.637\n",
      "Average Model AUC: 0.689\n"
     ]
    }
   ],
   "source": [
    "kfoldcrossvalidation(data, split_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 Accuracy: 0.715\n",
      "Split 2 Accuracy: 0.717\n",
      "Split 3 Accuracy: 0.721\n",
      "Split 4 Accuracy: 0.722\n",
      "Split 5 Accuracy: 0.723\n",
      "Split 6 Accuracy: 0.708\n",
      "Split 7 Accuracy: 0.715\n",
      "Split 8 Accuracy: 0.715\n",
      "Split 9 Accuracy: 0.716\n",
      "Split 10 Accuracy: 0.717\n",
      "Average Model Loss: 0.548\n",
      "Average Model Accuracy: 0.717\n",
      "Average Model AUC: 0.785\n"
     ]
    }
   ],
   "source": [
    "kfoldcrossvalidation(data, split_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 Accuracy: 0.709\n",
      "Split 2 Accuracy: 0.717\n",
      "Split 3 Accuracy: 0.721\n",
      "Split 4 Accuracy: 0.710\n",
      "Split 5 Accuracy: 0.716\n",
      "Split 6 Accuracy: 0.724\n",
      "Split 7 Accuracy: 0.717\n",
      "Split 8 Accuracy: 0.727\n",
      "Split 9 Accuracy: 0.717\n",
      "Split 10 Accuracy: 0.718\n",
      "Average Model Loss: 0.547\n",
      "Average Model Accuracy: 0.718\n",
      "Average Model AUC: 0.785\n"
     ]
    }
   ],
   "source": [
    "kfoldcrossvalidation(data, split_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizertest(optimizers=[]):\n",
    "    assert (len(optimizers) > 0), \"No optimizers specified in function call\"\n",
    "    for o in optimizers:\n",
    "        kfoldcrossvalidation(data, optimizer=o, epochs=2, sample_frac=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "l2_norm_clip=1.0\n",
    "noise_multiplier=1.1\n",
    "num_microbatches=1\n",
    "batch_size=256\n",
    "learning_rate=.15\n",
    "epochs=5\n",
    "population_size=len(data)\n",
    "\n",
    "privateop = privacy.optimizers.dp_optimizer.DPGradientDescentGaussianOptimizer(l2_norm_clip=l2_norm_clip,\n",
    "                                                                              noise_multiplier=noise_multiplier,\n",
    "                                                                              num_microbatches=num_microbatches,\n",
    "                                                                              learning_rate=learning_rate,\n",
    "                                                                              unroll_microbatches=True)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False, reduction=tf.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam test\n",
      "Split 1 Accuracy: 0.706\n",
      "Split 2 Accuracy: 0.696\n",
      "Split 3 Accuracy: 0.701\n",
      "Split 4 Accuracy: 0.695\n",
      "Split 5 Accuracy: 0.692\n",
      "Average Model Loss: 0.583\n",
      "Average Model Accuracy: 0.698\n",
      "Average Model AUC: 0.743\n",
      "<privacy.optimizers.dp_optimizer.make_gaussian_optimizer_class.<locals>.DPGaussianOptimizerClass object at 0x7f9516b34dd8> test\n",
      "Split 1 Accuracy: 0.510\n",
      "Split 2 Accuracy: 0.498\n",
      "Split 3 Accuracy: 0.496\n",
      "Split 4 Accuracy: 0.495\n",
      "Split 5 Accuracy: 0.502\n",
      "Average Model Loss: 0.742\n",
      "Average Model Accuracy: 0.500\n",
      "Average Model AUC: 0.513\n"
     ]
    }
   ],
   "source": [
    "optimizertest(optimizers=[\"adam\", privateop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64787 samples, validate on 16197 samples\n",
      "Epoch 1/50\n",
      "64787/64787 [==============================] - 3s 39us/step - loss: 343.2967 - acc: 0.5038 - auc: 0.4944 - val_loss: 830.5654 - val_acc: 0.5506 - val_auc: 0.5096\n",
      "Epoch 2/50\n",
      "64787/64787 [==============================] - 2s 28us/step - loss: 1776.0211 - acc: 0.5536 - auc: 0.5235 - val_loss: 2277.0548 - val_acc: 0.6323 - val_auc: 0.5370\n",
      "Epoch 3/50\n",
      "64787/64787 [==============================] - 2s 30us/step - loss: 2186.3911 - acc: 0.5805 - auc: 0.5486 - val_loss: 1594.3379 - val_acc: 0.4442 - val_auc: 0.5495\n",
      "Epoch 4/50\n",
      "64787/64787 [==============================] - 2s 30us/step - loss: 2003.9375 - acc: 0.5566 - auc: 0.5470 - val_loss: 3506.2222 - val_acc: 0.5186 - val_auc: 0.5475\n",
      "Epoch 5/50\n",
      "64787/64787 [==============================] - 2s 29us/step - loss: 4374.1005 - acc: 0.5398 - auc: 0.5458 - val_loss: 8798.5959 - val_acc: 0.4977 - val_auc: 0.5445\n",
      "Epoch 6/50\n",
      "64787/64787 [==============================] - 2s 30us/step - loss: 6450.0738 - acc: 0.5249 - auc: 0.5426 - val_loss: 8331.3487 - val_acc: 0.5673 - val_auc: 0.5415\n",
      "Epoch 7/50\n",
      "64787/64787 [==============================] - 2s 36us/step - loss: 5491.4909 - acc: 0.5261 - auc: 0.5408 - val_loss: 5124.3338 - val_acc: 0.5439 - val_auc: 0.5401\n",
      "Epoch 8/50\n",
      "64787/64787 [==============================] - 4s 60us/step - loss: 3616.0007 - acc: 0.5393 - auc: 0.5407 - val_loss: 2082.4333 - val_acc: 0.5134 - val_auc: 0.5397\n",
      "Epoch 9/50\n",
      "64787/64787 [==============================] - 4s 59us/step - loss: 668.7577 - acc: 0.5156 - auc: 0.5385 - val_loss: 23.5440 - val_acc: 0.5043 - val_auc: 0.5369\n",
      "Epoch 10/50\n",
      "64787/64787 [==============================] - 4s 59us/step - loss: 59.1399 - acc: 0.5033 - auc: 0.5362 - val_loss: 43.3480 - val_acc: 0.4976 - val_auc: 0.5360\n",
      "Epoch 11/50\n",
      "64787/64787 [==============================] - 4s 58us/step - loss: 46.7626 - acc: 0.5018 - auc: 0.5357 - val_loss: 46.3170 - val_acc: 0.5053 - val_auc: 0.5353\n",
      "Epoch 12/50\n",
      "64787/64787 [==============================] - 4s 60us/step - loss: 63.0857 - acc: 0.4991 - auc: 0.5348 - val_loss: 30.5207 - val_acc: 0.5018 - val_auc: 0.5343\n",
      "Epoch 13/50\n",
      "64787/64787 [==============================] - 4s 62us/step - loss: 75.9856 - acc: 0.4993 - auc: 0.5338 - val_loss: 219.0179 - val_acc: 0.4992 - val_auc: 0.5332\n",
      "Epoch 14/50\n",
      "64787/64787 [==============================] - 4s 62us/step - loss: 56.1964 - acc: 0.5017 - auc: 0.5326 - val_loss: 15.6592 - val_acc: 0.5040 - val_auc: 0.5321\n",
      "Epoch 15/50\n",
      "64787/64787 [==============================] - 4s 63us/step - loss: 29.0286 - acc: 0.4983 - auc: 0.5315 - val_loss: 1.7735 - val_acc: 0.4983 - val_auc: 0.5309\n",
      "Epoch 16/50\n",
      "64787/64787 [==============================] - 4s 62us/step - loss: 47.2545 - acc: 0.5016 - auc: 0.5303 - val_loss: 17.7295 - val_acc: 0.4984 - val_auc: 0.5298\n",
      "Epoch 17/50\n",
      "64787/64787 [==============================] - 4s 62us/step - loss: 81.6909 - acc: 0.5006 - auc: 0.5292 - val_loss: 85.8756 - val_acc: 0.5015 - val_auc: 0.5287\n",
      "Epoch 18/50\n",
      "64787/64787 [==============================] - 4s 62us/step - loss: 40.8462 - acc: 0.5013 - auc: 0.5281 - val_loss: 2.9978 - val_acc: 0.5026 - val_auc: 0.5277\n",
      "Epoch 19/50\n",
      "64787/64787 [==============================] - 4s 54us/step - loss: 11.0463 - acc: 0.5020 - auc: 0.5272 - val_loss: 7.8866 - val_acc: 0.4982 - val_auc: 0.5267\n",
      "Epoch 20/50\n",
      "64787/64787 [==============================] - 2s 35us/step - loss: 25.1877 - acc: 0.4983 - auc: 0.5262 - val_loss: 2.9040 - val_acc: 0.4982 - val_auc: 0.5257\n",
      "Epoch 21/50\n",
      "64787/64787 [==============================] - 2s 35us/step - loss: 16.8316 - acc: 0.5013 - auc: 0.5253 - val_loss: 0.9989 - val_acc: 0.5016 - val_auc: 0.5249\n",
      "Epoch 22/50\n",
      "64787/64787 [==============================] - 2s 33us/step - loss: 117.5792 - acc: 0.4984 - auc: 0.5245 - val_loss: 120.5807 - val_acc: 0.5016 - val_auc: 0.5241\n",
      "Epoch 23/50\n",
      "64787/64787 [==============================] - 1s 21us/step - loss: 85.1732 - acc: 0.5010 - auc: 0.5237 - val_loss: 9.1658 - val_acc: 0.4985 - val_auc: 0.5233\n",
      "Epoch 24/50\n",
      "64787/64787 [==============================] - 1s 20us/step - loss: 93.6233 - acc: 0.5018 - auc: 0.5229 - val_loss: 6.3786 - val_acc: 0.4986 - val_auc: 0.5225\n",
      "Epoch 25/50\n",
      "64787/64787 [==============================] - 1s 19us/step - loss: 306.3291 - acc: 0.4973 - auc: 0.5222 - val_loss: 108.9630 - val_acc: 0.5015 - val_auc: 0.5218\n",
      "Epoch 26/50\n",
      "64787/64787 [==============================] - 1s 20us/step - loss: 125.5249 - acc: 0.5030 - auc: 0.5215 - val_loss: 98.4183 - val_acc: 0.4985 - val_auc: 0.5212\n",
      "Epoch 27/50\n",
      "64787/64787 [==============================] - 1s 22us/step - loss: 173.8232 - acc: 0.5023 - auc: 0.5209 - val_loss: 166.6274 - val_acc: 0.4985 - val_auc: 0.5206\n",
      "Epoch 28/50\n",
      "64787/64787 [==============================] - 2s 33us/step - loss: 185.3889 - acc: 0.4986 - auc: 0.5203 - val_loss: 8.1834 - val_acc: 0.4984 - val_auc: 0.5200\n",
      "Epoch 29/50\n",
      "64787/64787 [==============================] - 2s 24us/step - loss: 89.9197 - acc: 0.5006 - auc: 0.5197 - val_loss: 40.9319 - val_acc: 0.4983 - val_auc: 0.5195\n",
      "Epoch 30/50\n",
      "64787/64787 [==============================] - 3s 48us/step - loss: 130.0973 - acc: 0.5026 - auc: 0.5192 - val_loss: 296.5236 - val_acc: 0.4983 - val_auc: 0.5189\n",
      "Epoch 31/50\n",
      "64787/64787 [==============================] - 2s 28us/step - loss: 253.5650 - acc: 0.4964 - auc: 0.5187 - val_loss: 127.2685 - val_acc: 0.5024 - val_auc: 0.5184\n",
      "Epoch 32/50\n",
      "64787/64787 [==============================] - 2s 28us/step - loss: 76.5996 - acc: 0.5025 - auc: 0.5182 - val_loss: 131.4366 - val_acc: 0.5021 - val_auc: 0.5180\n",
      "Epoch 33/50\n",
      "64787/64787 [==============================] - 1s 23us/step - loss: 116.3618 - acc: 0.4998 - auc: 0.5177 - val_loss: 165.2414 - val_acc: 0.5031 - val_auc: 0.5175\n",
      "Epoch 34/50\n",
      "64787/64787 [==============================] - 2s 35us/step - loss: 528.0676 - acc: 0.5010 - auc: 0.5173 - val_loss: 1206.4599 - val_acc: 0.4984 - val_auc: 0.5171\n",
      "Epoch 35/50\n",
      "64787/64787 [==============================] - 3s 40us/step - loss: 913.7074 - acc: 0.5010 - auc: 0.5169 - val_loss: 891.3463 - val_acc: 0.4983 - val_auc: 0.5167\n",
      "Epoch 36/50\n",
      "64787/64787 [==============================] - 3s 50us/step - loss: 998.0118 - acc: 0.5004 - auc: 0.5165 - val_loss: 683.8330 - val_acc: 0.4981 - val_auc: 0.5163\n",
      "Epoch 37/50\n",
      "64787/64787 [==============================] - 2s 33us/step - loss: 299.8905 - acc: 0.4959 - auc: 0.5160 - val_loss: 99.9385 - val_acc: 0.4984 - val_auc: 0.5158\n",
      "Epoch 38/50\n",
      "64787/64787 [==============================] - 3s 45us/step - loss: 279.7420 - acc: 0.4995 - auc: 0.5156 - val_loss: 22.8729 - val_acc: 0.5020 - val_auc: 0.5155\n",
      "Epoch 39/50\n",
      "64787/64787 [==============================] - 3s 39us/step - loss: 328.8914 - acc: 0.4978 - auc: 0.5153 - val_loss: 593.0227 - val_acc: 0.4984 - val_auc: 0.5151\n",
      "Epoch 40/50\n",
      "64787/64787 [==============================] - 2s 36us/step - loss: 278.3685 - acc: 0.5004 - auc: 0.5149 - val_loss: 508.2298 - val_acc: 0.5021 - val_auc: 0.5148\n",
      "Epoch 41/50\n",
      "64787/64787 [==============================] - 3s 42us/step - loss: 434.0733 - acc: 0.5003 - auc: 0.5147 - val_loss: 448.8594 - val_acc: 0.5018 - val_auc: 0.5145\n",
      "Epoch 42/50\n",
      "64787/64787 [==============================] - 2s 35us/step - loss: 561.7648 - acc: 0.4999 - auc: 0.5144 - val_loss: 569.1065 - val_acc: 0.5019 - val_auc: 0.5142\n",
      "Epoch 43/50\n",
      "64787/64787 [==============================] - 1s 22us/step - loss: 214.1048 - acc: 0.5020 - auc: 0.5141 - val_loss: 68.0201 - val_acc: 0.4984 - val_auc: 0.5140\n",
      "Epoch 44/50\n",
      "64787/64787 [==============================] - 1s 21us/step - loss: 111.5929 - acc: 0.5024 - auc: 0.5138 - val_loss: 175.7223 - val_acc: 0.5014 - val_auc: 0.5137\n",
      "Epoch 45/50\n",
      "64787/64787 [==============================] - 1s 19us/step - loss: 770.5831 - acc: 0.5011 - auc: 0.5136 - val_loss: 155.0702 - val_acc: 0.5018 - val_auc: 0.5135\n",
      "Epoch 46/50\n",
      "64787/64787 [==============================] - 1s 19us/step - loss: 326.6494 - acc: 0.4998 - auc: 0.5133 - val_loss: 187.3877 - val_acc: 0.5012 - val_auc: 0.5132\n",
      "Epoch 47/50\n",
      "64787/64787 [==============================] - 1s 18us/step - loss: 610.3888 - acc: 0.5029 - auc: 0.5131 - val_loss: 204.6542 - val_acc: 0.5015 - val_auc: 0.5130\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64787/64787 [==============================] - 1s 21us/step - loss: 433.6558 - acc: 0.4993 - auc: 0.5129 - val_loss: 871.5193 - val_acc: 0.4982 - val_auc: 0.5128\n",
      "Epoch 49/50\n",
      "64787/64787 [==============================] - 1s 19us/step - loss: 606.6972 - acc: 0.5008 - auc: 0.5126 - val_loss: 239.2328 - val_acc: 0.5018 - val_auc: 0.5125\n",
      "Epoch 50/50\n",
      "64787/64787 [==============================] - 1s 19us/step - loss: 579.3308 - acc: 0.5007 - auc: 0.5124 - val_loss: 369.9285 - val_acc: 0.4982 - val_auc: 0.5123\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 100)               2000      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 25)                2525      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 20)                520       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 5,087\n",
      "Trainable params: 5,087\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_creation(optimizer=privateop, loss=loss)\n",
    "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test), batch_size=256)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      " [[5059 3013]\n",
      " [4346 3779]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "rounded = np.rint(predictions)\n",
    "\n",
    "con_mat = tf.confusion_matrix(labels=np.argmax(y_test, axis=1),predictions=np.argmax(predictions, axis=1), num_classes=2, dtype=tf.int32, name=None)\n",
    "\n",
    "with tf.Session():\n",
    "   print('Confusion Matrix: \\n\\n', tf.Tensor.eval(con_mat,feed_dict=None, session=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
